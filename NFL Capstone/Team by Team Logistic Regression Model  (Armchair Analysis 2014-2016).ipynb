{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abir.deb/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/abir.deb/anaconda2/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import csv\n",
    "import timeit\n",
    "from sys import platform\n",
    "from IPython.core.display import HTML\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "def cv_score(clf, x, y, score_func=accuracy_score):\n",
    "    result = 0\n",
    "    nfold = 5\n",
    "    for train, test in KFold(y.size, nfold): # split data into train/test groups, 5 times\n",
    "        clf.fit(x[train], y[train]) # fit\n",
    "        result += score_func(clf.predict(x[test]), y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average\n",
    "\n",
    "\n",
    "\n",
    "def replace_STL_with_LA(GAME_df, DRIVE_df, PLAY_df):\n",
    "    '''\n",
    "    replaces all instances of 'STL' with 'LA' returns the altered dataframe; this is to stay\n",
    "    consistent with the NFL Savant modeling approach since 'STL' and 'LA' are both the same Rams franchise/team\n",
    "    '''\n",
    "    #change certain columns in GAME_df\n",
    "    GAME_df['h'] = GAME_df['h'].replace(to_replace = 'STL', value = 'LA')\n",
    "    GAME_df['v'] = GAME_df['v'].replace(to_replace = 'STL', value = 'LA')\n",
    "    \n",
    "    #change certain columns in DRIVE_df\n",
    "    DRIVE_df['tname'] = DRIVE_df['tname'].replace(to_replace = 'STL', value = 'LA')\n",
    "    \n",
    "    #change certain columns in PLAY_df\n",
    "    PLAY_df['off'] = PLAY_df['off'].replace(to_replace = 'STL', value = 'LA')\n",
    "    PLAY_df['def'] = PLAY_df['def'].replace(to_replace = 'STL', value = 'LA')\n",
    "    \n",
    "    return [GAME_df, DRIVE_df, PLAY_df]\n",
    "\n",
    "\n",
    "def load_data(dir, lst_files_to_load, path_slash):\n",
    "    '''\n",
    "    LOAD DATA from dir that contains data files in csv format; path_slash contains a string used for directories\n",
    "    #in a path ('/' in Unix based system or '\\\\' in Windows)\n",
    "    '''\n",
    "    files = os.listdir(dir)\n",
    "    #initialize a dictionary to store csv files\n",
    "    data_dict = {}\n",
    "    for fil in files:\n",
    "        if fil in lst_files_to_load:\n",
    "            filePath = dir + path_slash + fil\n",
    "            data_dict[fil[:-4]] = pd.DataFrame.from_csv(filePath)\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "\n",
    "def generate_teams_lst(df, year):\n",
    "    #stores all the team abbreviation (assuming dataframe passed is GAME_df)\n",
    "    df = df[df.seas == year]\n",
    "    teams = df.h.dropna().drop_duplicates().sort_values()\n",
    "    return list(teams)\n",
    "\n",
    "\n",
    "\n",
    "def check_number_of_teams(df, team_of_interest):\n",
    "    '''\n",
    "    debugging check for distinct number of teams (home and away) that faces the team of interest\n",
    "    when joining drive and game data together and filtering out for year and team of interest\n",
    "    '''\n",
    "    home_teams = list(df.h.drop_duplicates())\n",
    "    away_teams = list(df.v.drop_duplicates())\n",
    "    all_teams = home_teams + away_teams\n",
    "    \n",
    "    #get rid of entries that are the team of interest\n",
    "    for entry in all_teams:\n",
    "        if entry == team_of_interest:\n",
    "            all_teams.remove(entry)\n",
    "    \n",
    "    return [len(set(all_teams)), set(all_teams)]\n",
    "\n",
    "\n",
    "\n",
    "def train_test_qc_check(train, test):\n",
    "    '''\n",
    "    check that the labels for the train and test sets are the same and in the same order; this makes sure\n",
    "    there are no errors when performing linear algebra on the matrices when building the model; returns\n",
    "    True if all the column labels are in the same and in the same order, False otherwise\n",
    "    '''\n",
    "    train_columns = list(train.columns)\n",
    "    test_columns = list(test.columns)\n",
    "    \n",
    "    #make sure both the train and test sets have the same number of columns\n",
    "    if len(train_columns) != len(test_columns):\n",
    "        return False\n",
    "    \n",
    "    #make sure every column is the same for both the train and test sets; return True if it passes this block\n",
    "    for i in range(len(train_columns)):\n",
    "        if train_columns[i] != test_columns[i]:\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def gather_drive_data(GAME_df, DRIVE_df, year, team):\n",
    "    '''\n",
    "    This function filters drive data by team and year and returns DRIVE_df with 'gid', 'fpid', and 'plays'\n",
    "    which are all necessary to gather play by play data in later step\n",
    "    '''\n",
    "    columns_of_interest = ['gid', 'fpid', 'plays', 'h', 'v']\n",
    "    GAME_df_filtered = GAME_df[GAME_df.seas == year]\n",
    "    DRIVE_df_filtered = DRIVE_df[DRIVE_df.tname == team]\n",
    "    GAME_DRIVE_joined_df = DRIVE_df_filtered.join(GAME_df_filtered, on = 'gid', how = 'inner')\n",
    "    \n",
    "    return GAME_DRIVE_joined_df[columns_of_interest]\n",
    "\n",
    "\n",
    "\n",
    "def gather_game_ids(df):\n",
    "    '''\n",
    "    drive_data_df will be passed here and gameIDs will be gathered and returned in a list\n",
    "    '''\n",
    "    game_id_list = list(df.gid.dropna().drop_duplicates())\n",
    "    \n",
    "    return game_id_list\n",
    "\n",
    "\n",
    "def create_train_test_set(df, rand_state):\n",
    "    '''\n",
    "    This function creates a train and test set for each game in the filtered drive data (drive_data_df); this ensures\n",
    "    that each team has a balanced amount of drives in the train and test set for each and every game in a given season\n",
    "    '''\n",
    "    #TO DO: iterate through each gameID and filter out those drives and create a separate train/test set for each\n",
    "    #game so this ensures there's drives for every game in the train/test set, then combine all the dfs and return\n",
    "    #the train/test df's of drive data\n",
    "    game_id_lst = gather_game_ids(df)\n",
    "    train_set_df_lst = []\n",
    "    test_set_df_lst = []\n",
    "    \n",
    "    for gameid in game_id_lst:\n",
    "        drives_subset_df = df[df.gid == gameid]\n",
    "        drive_train, drive_test = train_test_split(drives_subset_df, random_state = rand_state)\n",
    "        train_set_df_lst.append(drive_train)\n",
    "        test_set_df_lst.append(drive_test)\n",
    "    \n",
    "    return [pd.concat(train_set_df_lst, copy = False), pd.concat(test_set_df_lst, copy = False)]\n",
    "\n",
    "    \n",
    "def find_plays(first_play_id, num_plays, sub_play_df):\n",
    "    '''\n",
    "    return a data frame with all the plays (RUN OR PASS) from a given first_play_id, num_plays and sub_play_df\n",
    "    (which contains all the plays we need to filter out and return as a data frame)\n",
    "    '''\n",
    "    columns_of_interest = [\n",
    "        'pid', 'off', 'def', 'type', 'qtr', 'min', 'sec'\n",
    "        , 'ptso', 'ptsd', 'dwn', 'ytg', 'yfog', 'zone'\n",
    "         , 'sg', 'nh', 'timo', 'timd'\n",
    "    ]\n",
    "    \n",
    "    #calculate the last play's play_id\n",
    "    last_play_id = first_play_id + num_plays\n",
    "    \n",
    "    #gather all the pass/rush plays from sub_play_df using the range of play_ids given for the drive\n",
    "    all_plays_in_drive = sub_play_df[np.logical_and(np.logical_or(sub_play_df.type == 'PASS', sub_play_df.type == 'RUSH'),\n",
    "                                            np.logical_and(sub_play_df.pid >= first_play_id, sub_play_df.pid < last_play_id))]\n",
    "    \n",
    "    return all_plays_in_drive[columns_of_interest]\n",
    "\n",
    "\n",
    "\n",
    "def add_under_center_column(df):\n",
    "    '''\n",
    "    This function takes in play by play data frame and adds in an under_center column (uc) and returns the data frame\n",
    "    '''\n",
    "    df['uc'] = np.int64(df['sg'] == 0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def gather_play_by_play_data(drive_data_df, PLAY_df):\n",
    "    '''\n",
    "    This function returns the play by play data in a data frame from the given drive data and PLAY_df\n",
    "    '''\n",
    "    plays_df_lst = [] #holds all the play by play data frames in one list\n",
    "    game_id = None #will hold the current game_id of interest\n",
    "\n",
    "    for lab, row in drive_data_df.iterrows():\n",
    "        #gather necessary variables to extract play by play data\n",
    "        first_play_id = row[1]\n",
    "        num_plays = row[2]\n",
    "        \n",
    "        #we don't want to keep extracting the same game's data every iteration unless it's a new game_id\n",
    "        if game_id != row[0]:\n",
    "            game_id = row[0]\n",
    "            sub_play_df = PLAY_df.loc[game_id] #partition PLAY_df to play data of interest\n",
    "\n",
    "        #gather all the plays for this specific drive and store it in plays_df_lst\n",
    "        all_plays_in_drive = find_plays(first_play_id, num_plays, sub_play_df)\n",
    "        \n",
    "        #add data frame of plays to list\n",
    "        plays_df_lst.append(all_plays_in_drive)\n",
    "        \n",
    "    #return all play by play data concatenated and add under center column\n",
    "    return add_under_center_column(pd.concat(plays_df_lst, copy = False))\n",
    "\n",
    "    \n",
    "\n",
    "def create_x_y_matrix(df):\n",
    "    '''\n",
    "    This function creates the x and y vector for each data frame with play by play data\n",
    "    '''\n",
    "    X = df.drop('type', axis = 1)\n",
    "    y = df.type.to_frame('play_type')\n",
    "    \n",
    "    return [X, y]\n",
    "    \n",
    "    \n",
    "    \n",
    "def preprocess_data(df):\n",
    "    '''\n",
    "    This function will apply preprocessing steps to the train and test set so that they are\n",
    "    ready for model building\n",
    "    '''\n",
    "    features = [\n",
    "        'off', 'def', 'qtr', 'min', 'sec'\n",
    "        , 'ptso', 'ptsd', 'dwn', 'ytg', 'yfog', 'zone'\n",
    "         , 'sg', 'nh', 'uc', 'timo', 'timd'\n",
    "    ]\n",
    "    \n",
    "    #will create X (design matrix) and y (result vector)\n",
    "    X, y = create_x_y_matrix(df)\n",
    "    \n",
    "    #rename column 'type' to 'play_type'\n",
    "    #X.rename(columns = {'type': 'play_type'}, inplace = True)\n",
    "    \n",
    "    #take columns of interest\n",
    "    X_subset = X[features]\n",
    "    \n",
    "    #drop rows that have NaNs in any column\n",
    "    X_final = X_subset.dropna()\n",
    "    \n",
    "    #create a label encoding in y dataframe since 'play_type' is the variable we are trying to predict\n",
    "    y.play_type = y.play_type.astype('category')\n",
    "    y['play_type_cat'] = y.play_type.cat.codes\n",
    "    \n",
    "    #create dummy variables for each feature that is categorical or an indicator variable\n",
    "    #(off, def, sg, nh, uc, and zone)\n",
    "    X_final = pd.get_dummies(X_final, columns = ['off', 'def', 'zone'])\n",
    "    \n",
    "    return [X_final, y]\n",
    "\n",
    "\n",
    "\n",
    "def round_array(array):\n",
    "    '''return a list of floats that have been rounded from given array'''\n",
    "    lst_to_return = []\n",
    "    for entry in array:\n",
    "        lst_to_return.append(round(entry))\n",
    "    return lst_to_return\n",
    "\n",
    "\n",
    "\n",
    "def run_data_wrangling_process(year, team):\n",
    "    '''\n",
    "    This function begins the data wrangling/ETL process on the loaded data\n",
    "    and returns the train and test set data frames ready for model building\n",
    "    '''\n",
    "    #gather all the necessary drive data for particular year\n",
    "    drive_data_df = gather_drive_data(GAME_df, DRIVE_df, year, team)\n",
    "    \n",
    "    #create a train and test set of the drive data\n",
    "    drive_train, drive_test = create_train_test_set(drive_data_df, rand_state = 69)\n",
    "    \n",
    "    '''\n",
    "    #debugging check\n",
    "    print team\n",
    "    num_teams_train_set, all_teams_train = check_number_of_teams(drive_train, team)\n",
    "    num_teams_test_set, all_teams_test = check_number_of_teams(drive_test, team)\n",
    "    print 'Number of teams in training set', num_teams_train_set\n",
    "    print all_teams_train\n",
    "    print 'Number of teams in testing set', num_teams_test_set\n",
    "    print all_teams_test\n",
    "    all_teams_train_set = set(all_teams_train)\n",
    "    all_teams_test_set = set(all_teams_test)\n",
    "    print 'Team in train or test, but not in both', all_teams_train_set.symmetric_difference(all_teams_test_set)\n",
    "    print '\\n'\n",
    "    '''\n",
    "    \n",
    "    #derive the play by play data from the drive data train and test sets (all plays in each drive stay within each set)\n",
    "    X_train, y_train = preprocess_data(gather_play_by_play_data(drive_train, PLAY_df))\n",
    "    X_test, y_test = preprocess_data(gather_play_by_play_data(drive_test, PLAY_df))\n",
    "    \n",
    "    return [X_train, y_train, X_test, y_test]\n",
    "\n",
    "\n",
    "\n",
    "def build_model(X_train, y_train, X_test, y_test, year, team):\n",
    "    '''\n",
    "    This function builds the model from a train and test set and gathers model evaluation metrics\n",
    "    '''\n",
    "    #fit a logistic regression model\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #accuracy score on train data\n",
    "    train_accuracy_score_no_grid = accuracy_score(clf.predict(X_train), y_train)\n",
    "    \n",
    "    #accuracy score on test data\n",
    "    test_accuracy_score_no_grid = accuracy_score(clf.predict(X_test), y_test)\n",
    "    \n",
    "    #5 Fold Cross Validation Accuracy\n",
    "    five_fold_cv_score_no_grid = cv_score(clf, X_train, y_train)\n",
    "    \n",
    "    #the grid of parameters to search over\n",
    "    Cs = [0.001, 0.1, 1, 10, 100]\n",
    "    param_grid = {'C' : Cs }\n",
    "    model = GridSearchCV(LogisticRegression(), param_grid, scoring = 'accuracy', cv = 5)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #best regularization parameter from grid search\n",
    "    best_reg = model.best_params_['C']\n",
    "    \n",
    "    #test set accuracy with the best regularization parameter\n",
    "    test_accuracy_best_reg = accuracy_score(model.predict(X_test), y_test)\n",
    "    \n",
    "    #gather model metrics using the best regularization parameter\n",
    "    preds = model.predict_proba(X_test)[:,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, preds)\n",
    "\n",
    "    y_test_rounded = round_array(y_test)\n",
    "    preds_rounded = round_array(preds)\n",
    "\n",
    "    #precision (true positives / [true positives + false positives])\n",
    "    precision = metrics.precision_score(y_test_rounded, preds_rounded)\n",
    "\n",
    "    #recall (true positives / [true positives + false negatives])\n",
    "    recall = metrics.recall_score(y_test_rounded, preds_rounded)\n",
    "\n",
    "    #F1 score is the geometric/harmonic mean of precision and recall; 2 * tp / ( 2 * tp + fp + fn)\n",
    "    f1_score = metrics.f1_score(y_test_rounded, preds_rounded)\n",
    "    \n",
    "    #AUC\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    #list of metrics\n",
    "    metrics_lst = [\n",
    "        year,\n",
    "        team,\n",
    "        train_accuracy_score_no_grid,\n",
    "        test_accuracy_score_no_grid,\n",
    "        five_fold_cv_score_no_grid,\n",
    "        best_reg,\n",
    "        test_accuracy_best_reg,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1_score,\n",
    "        auc\n",
    "    ]\n",
    "    \n",
    "    #rates to make ROC curve\n",
    "    roc_curve_metrics = [year, fpr, tpr, auc]\n",
    "    \n",
    "    #gather model coefficients\n",
    "    model_coefficients_tup = tuple(model.best_estimator_.coef_[0].tolist())\n",
    "    \n",
    "    lst_to_return = [metrics_lst, roc_curve_metrics]\n",
    "    \n",
    "    return lst_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are the relational tables in csv format to load into pandas data frames\n",
    "lst_files_to_load = ['DRIVE.csv', 'GAME.csv', 'PLAY.csv']\n",
    "\n",
    "#make sure directory paths are correct based on running in a Windows/Unix environment\n",
    "if platform == 'win32':\n",
    "    #code is running in a windows machine\n",
    "    dir_files_to_load = os.getcwd() + '\\\\armchair\\\\nfl_00-16'\n",
    "    data_dict = load_data(dir_files_to_load, lst_files_to_load, '\\\\')\n",
    "    metrics_csv_file_path = os.getcwd() + '\\\\armchair_all_data_model_metrics.csv'\n",
    "else:\n",
    "    dir_files_to_load = os.getcwd() + '/armchair/nfl_00-16'\n",
    "    data_dict = load_data(dir_files_to_load, lst_files_to_load, '/')\n",
    "    metrics_csv_file_path = os.getcwd() + '/armchair_all_data_model_metrics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create all the variables for the dataframes in the data_dict\n",
    "for df in data_dict.keys():\n",
    "    command = str(df) + '_df' + ' = data_dict[\"' + str(df) + '\"]'\n",
    "    #print command\n",
    "    exec(command)\n",
    "    \n",
    "'''\n",
    "let's replace STL with LA in all the based dataframes to stay consistent with our team based logistic regression\n",
    "approach with NFL Savant data; STL becomes LA in 2016, so we are assuming STL was LA in 2014-2015 as well just to\n",
    "stay consistent from a modeling perspective (they are both the same Rams franchise/same team, just relocated)\n",
    "'''\n",
    "GAME_df, DRIVE_df, PLAY_df = replace_STL_with_LA(GAME_df, DRIVE_df, PLAY_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years = [2014, 2015, 2016]\n",
    "model_metrics_lsts = [] #will hold all the model metrics for each model generated for each team in each season\n",
    "roc_curve_rates = [] #will hold fpr & tpr to build ROC curve\n",
    "columns = [\n",
    "        'year',\n",
    "        'team',\n",
    "        'train_accuracy_score_no_grid',\n",
    "        'test_accuracy_score_no_grid',\n",
    "        'five_fold_cv_score_no_grid',\n",
    "        'best_reg',\n",
    "        'test_accuracy_best_reg',\n",
    "        'precision',\n",
    "        'recall',\n",
    "        'f1_score',\n",
    "        'auc'\n",
    "    ]\n",
    "\n",
    "\n",
    "for year in years:\n",
    "    #generate a new list of teams for each season (teams may be different in certain seasons)\n",
    "    teams_lst = generate_teams_lst(GAME_df, year)\n",
    "    for team in teams_lst:\n",
    "        X_train, y_train, X_test, y_test = run_data_wrangling_process(year, team)\n",
    "        \n",
    "        #QC for train and test set transformations (from drive train/tests to play by play train/test sets)\n",
    "        result_x = train_test_qc_check(X_train, X_test)\n",
    "        result_y = train_test_qc_check(y_train, y_test)\n",
    "        \n",
    "        if result_x == False:\n",
    "            print team, year, 'X_train and X_test mismatch'\n",
    "            \n",
    "        if result_y == False:\n",
    "            print team, year, 'y_train and y_test mismatch'\n",
    "            \n",
    "        #each year's metrics results will be held in metrics_lst, tpr & fpr are used for ROC Curve\n",
    "        model_metrics_lst, roc_curve_metrics = build_model(X_train.values, y_train['play_type_cat'].values\n",
    "                                                     , X_test, y_test['play_type_cat'].values, year, team)\n",
    "        model_metrics_lsts.append(model_metrics_lst)\n",
    "    \n",
    "#convert metrics_lsts into a dataframe\n",
    "metrics_df = pd.DataFrame(model_metrics_lsts, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>team</th>\n",
       "      <th>train_accuracy_score_no_grid</th>\n",
       "      <th>test_accuracy_score_no_grid</th>\n",
       "      <th>five_fold_cv_score_no_grid</th>\n",
       "      <th>best_reg</th>\n",
       "      <th>test_accuracy_best_reg</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>ARI</td>\n",
       "      <td>0.769452</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.762308</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.810397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0.749650</td>\n",
       "      <td>0.733083</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.663551</td>\n",
       "      <td>0.779725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>BAL</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.701608</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.682119</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.627737</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.768016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0.755650</td>\n",
       "      <td>0.671815</td>\n",
       "      <td>0.700659</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.691120</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.748491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>CAR</td>\n",
       "      <td>0.661597</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>0.626026</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.654494</td>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.530488</td>\n",
       "      <td>0.585859</td>\n",
       "      <td>0.717734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014</td>\n",
       "      <td>CHI</td>\n",
       "      <td>0.732746</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.690146</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.688462</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.430108</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.725195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>CIN</td>\n",
       "      <td>0.772666</td>\n",
       "      <td>0.724382</td>\n",
       "      <td>0.748272</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.703180</td>\n",
       "      <td>0.690141</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.776462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014</td>\n",
       "      <td>CLE</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.630435</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.781476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014</td>\n",
       "      <td>DAL</td>\n",
       "      <td>0.861601</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.860314</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.827692</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.858896</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.872037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014</td>\n",
       "      <td>DEN</td>\n",
       "      <td>0.731469</td>\n",
       "      <td>0.674487</td>\n",
       "      <td>0.714685</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.723214</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.595588</td>\n",
       "      <td>0.765055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2014</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.774366</td>\n",
       "      <td>0.712418</td>\n",
       "      <td>0.758353</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.645669</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.653386</td>\n",
       "      <td>0.786379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2014</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.761273</td>\n",
       "      <td>0.662420</td>\n",
       "      <td>0.717316</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.659236</td>\n",
       "      <td>0.650943</td>\n",
       "      <td>0.496403</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>0.710545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014</td>\n",
       "      <td>HOU</td>\n",
       "      <td>0.759547</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>0.738288</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.693069</td>\n",
       "      <td>0.678363</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.713846</td>\n",
       "      <td>0.740521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2014</td>\n",
       "      <td>IND</td>\n",
       "      <td>0.728121</td>\n",
       "      <td>0.638122</td>\n",
       "      <td>0.712940</td>\n",
       "      <td>100.000</td>\n",
       "      <td>0.638122</td>\n",
       "      <td>0.465649</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.482213</td>\n",
       "      <td>0.665984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2014</td>\n",
       "      <td>JAC</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.750725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014</td>\n",
       "      <td>KC</td>\n",
       "      <td>0.719156</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678547</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.595420</td>\n",
       "      <td>0.607004</td>\n",
       "      <td>0.705095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014</td>\n",
       "      <td>LA</td>\n",
       "      <td>0.760671</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.745478</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.742616</td>\n",
       "      <td>0.689076</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.817442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014</td>\n",
       "      <td>MIA</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>0.608553</td>\n",
       "      <td>0.669161</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.595395</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.336283</td>\n",
       "      <td>0.381910</td>\n",
       "      <td>0.588241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.715339</td>\n",
       "      <td>0.698842</td>\n",
       "      <td>0.670948</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.687259</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.725590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014</td>\n",
       "      <td>NE</td>\n",
       "      <td>0.771327</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.745301</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.757333</td>\n",
       "      <td>0.613095</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.812535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year team  train_accuracy_score_no_grid  test_accuracy_score_no_grid  \\\n",
       "0   2014  ARI                      0.769452                     0.757143   \n",
       "1   2014  ATL                      0.749650                     0.733083   \n",
       "2   2014  BAL                      0.734513                     0.682119   \n",
       "3   2014  BUF                      0.755650                     0.671815   \n",
       "4   2014  CAR                      0.661597                     0.651685   \n",
       "5   2014  CHI                      0.732746                     0.688462   \n",
       "6   2014  CIN                      0.772666                     0.724382   \n",
       "7   2014  CLE                      0.728571                     0.692000   \n",
       "8   2014  DAL                      0.861601                     0.827692   \n",
       "9   2014  DEN                      0.731469                     0.674487   \n",
       "10  2014  DET                      0.774366                     0.712418   \n",
       "11  2014   GB                      0.761273                     0.662420   \n",
       "12  2014  HOU                      0.759547                     0.679868   \n",
       "13  2014  IND                      0.728121                     0.638122   \n",
       "14  2014  JAC                      0.747126                     0.716049   \n",
       "15  2014   KC                      0.719156                     0.666667   \n",
       "16  2014   LA                      0.760671                     0.746835   \n",
       "17  2014  MIA                      0.683900                     0.608553   \n",
       "18  2014  MIN                      0.715339                     0.698842   \n",
       "19  2014   NE                      0.771327                     0.752000   \n",
       "\n",
       "    five_fold_cv_score_no_grid  best_reg  test_accuracy_best_reg  precision  \\\n",
       "0                     0.762308     0.100                0.757143   0.682927   \n",
       "1                     0.707692     0.100                0.729323   0.586777   \n",
       "2                     0.701608     0.100                0.682119   0.656489   \n",
       "3                     0.700659     0.100                0.691120   0.611111   \n",
       "4                     0.626026     0.100                0.654494   0.654135   \n",
       "5                     0.690146     0.100                0.688462   0.588235   \n",
       "6                     0.748272     0.100                0.703180   0.690141   \n",
       "7                     0.710000     0.100                0.688000   0.630435   \n",
       "8                     0.860314     0.100                0.827692   0.809249   \n",
       "9                     0.714685     0.100                0.677419   0.723214   \n",
       "10                    0.758353     0.100                0.715686   0.645669   \n",
       "11                    0.717316     0.100                0.659236   0.650943   \n",
       "12                    0.738288     0.100                0.693069   0.678363   \n",
       "13                    0.712940   100.000                0.638122   0.465649   \n",
       "14                    0.709877     0.100                0.703704   0.703704   \n",
       "15                    0.678547     0.100                0.659933   0.619048   \n",
       "16                    0.745478     0.100                0.742616   0.689076   \n",
       "17                    0.669161     0.001                0.595395   0.441860   \n",
       "18                    0.670948     0.100                0.687259   0.666667   \n",
       "19                    0.745301     0.100                0.757333   0.613095   \n",
       "\n",
       "      recall  f1_score       auc  \n",
       "0   0.743363  0.711864  0.810397  \n",
       "1   0.763441  0.663551  0.779725  \n",
       "2   0.627737  0.641791  0.768016  \n",
       "3   0.550000  0.578947  0.748491  \n",
       "4   0.530488  0.585859  0.717734  \n",
       "5   0.430108  0.496894  0.725195  \n",
       "6   0.710145  0.700000  0.776462  \n",
       "7   0.763158  0.690476  0.781476  \n",
       "8   0.858896  0.833333  0.872037  \n",
       "9   0.506250  0.595588  0.765055  \n",
       "10  0.661290  0.653386  0.786379  \n",
       "11  0.496403  0.563265  0.710545  \n",
       "12  0.753247  0.713846  0.740521  \n",
       "13  0.500000  0.482213  0.665984  \n",
       "14  0.542857  0.612903  0.750725  \n",
       "15  0.595420  0.607004  0.705095  \n",
       "16  0.773585  0.728889  0.817442  \n",
       "17  0.336283  0.381910  0.588241  \n",
       "18  0.578947  0.619718  0.725590  \n",
       "19  0.798450  0.693603  0.812535  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**write metrics_df to a csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics_df.to_csv(metrics_csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.2 sec\n",
      "0.89 min\n"
     ]
    }
   ],
   "source": [
    "stop = timeit.default_timer()\n",
    "program_time_in_sec = stop - start\n",
    "program_time_in_min = program_time_in_sec / 60.0\n",
    "print str(round(program_time_in_sec, 1)), 'sec'\n",
    "print str(round(program_time_in_min, 2)), 'min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
